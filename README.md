# ğŸ³ NYTimes Microservices - OrquestraÃ§Ã£o

Este repositÃ³rio Ã© responsÃ¡vel por orquestrar os serviÃ§os do projeto NYTimes utilizando Docker Compose.

âš ï¸ Ele **nÃ£o contÃ©m lÃ³gica de negÃ³cio**.  
Sua Ãºnica responsabilidade Ã© gerenciar a infraestrutura e a integraÃ§Ã£o entre os serviÃ§os.

---

## ğŸ—ï¸ Arquitetura

O sistema Ã© composto por trÃªs serviÃ§os principais:

- ğŸ“° **Scraper** â†’ Coleta notÃ­cias do NYTimes utilizando Selenium
- ğŸš€ **API** â†’ Recebe, valida e persiste as notÃ­cias
- ğŸ—„ï¸ **PostgreSQL** â†’ Banco de dados relacional

### Fluxo de comunicaÃ§Ã£o

[ Scraper ] ---> [ API ] ---> [ PostgreSQL ]

---

## ğŸ“¦ RepositÃ³rios NecessÃ¡rios

Antes de executar este projeto, Ã© necessÃ¡rio clonar os seguintes repositÃ³rios no mesmo diretÃ³rio raiz:

- ğŸ‘‰ https://github.com/fellipeafonseca/prj_python-api-nytimes
- ğŸ‘‰ https://github.com/fellipeafonseca/prj_python-rpa-nytimes-scraper

---

## ğŸ“ Estrutura Esperada de Pastas

Todos os repositÃ³rios devem estar no mesmo nÃ­vel:

workspace/
â”œâ”€â”€ nytimes-api/
â”œâ”€â”€ nytimes-scraper/
â””â”€â”€ nytimes-orchestration/


âš ï¸ Os nomes das pastas devem corresponder exatamente aos caminhos definidos no `docker-compose.yml`.

---

## ğŸš€ Como Executar o Sistema Completo

### 1ï¸âƒ£ Clonar os repositÃ³rios

```bash
git clone https://github.com/SEU_USUARIO/nytimes-api
git clone https://github.com/SEU_USUARIO/nytimes-scraper
git clone https://github.com/SEU_USUARIO/nytimes-orchestration
```

2ï¸âƒ£ Acessar a pasta de orquestraÃ§Ã£o
```
cd nytimes-orchestration
```

3ï¸âƒ£ Subir os containers
```
docker compose up --build
```

## ğŸŒ ServiÃ§os DisponÃ­veis

### ApÃ³s a inicializaÃ§Ã£o:

ServiÃ§o	URL
API (Swagger)	http://localhost:8000/docs
Banco de Dados	localhost:5432

## ğŸ”§ VariÃ¡veis de Ambiente

As variÃ¡veis estÃ£o definidas diretamente no docker-compose.yml.
Para ambientes mais avanÃ§ados (produÃ§Ã£o), recomenda-se utilizar um arquivo .env.

## ğŸ§  DecisÃµes de Arquitetura

Cada serviÃ§o possui seu prÃ³prio repositÃ³rio
ComunicaÃ§Ã£o entre serviÃ§os ocorre via rede interna do Docker
O Scraper envia dados para a API via HTTP
A API valida e persiste os dados no PostgreSQL
A infraestrutura Ã© gerenciada exclusivamente pelo Docker Compose
Essa abordagem segue princÃ­pios de separaÃ§Ã£o de responsabilidades e permite que cada serviÃ§o seja versionado e implantado de forma independente.

## ğŸ“Œ ObservaÃ§Ãµes Importantes

O Scraper Ã© executado como serviÃ§o independente
A API nÃ£o depende do Scraper para funcionar
Este repositÃ³rio existe apenas para orquestraÃ§Ã£o da infraestrutura











